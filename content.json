{"posts":[{"title":"为什么不可以emplace_back({1, 2})?","text":"在cpp代码中，我们可以写出如下的代码： 12vector&lt;pair&lt;int, int&gt;&gt; vec;vec.push_back({1, 2}); 然而，vec.emplace_back({1, 2})会报错，我们只能vec.emplace_back(1, 2)。 why push_back works?对于void push_back( T&amp;&amp; value )，由于下面这两条规则，我们可以使用一个braced-init-list作为函数的参数（所谓的braced-init-list就是大括号）。 https://vinci-897.github.io/cppwp/n4868/dcl.init.list#1.5 https://vinci-897.github.io/cppwp/n4868/dcl.init.list#3.7 由于下面这一条规则，我们最终找到了这一条构造函数 https://vinci-897.github.io/cppwp/n4868/over.match#list-1.2 why emplace_back not works with a braced-list?对于vec.emplace_back(1, 2)，只是一个std::forward参数转发，vector会调用allocator_trait的construct函数执行一个placement new来构造参数。 https://en.cppreference.com/w/cpp/container/vector/emplace_back 而对于vec.emplace_back({1, 2})，由于emplace_back的函数签名是 在cpp中，由于以下的规则，不支持在函数参数中由一个大括号的参数把一个完全空白的模版参数T推断成完整的initializer_list&lt;int&gt;，因此clang会给出类似template deduction failed的报错(然而auto是支持这种推导的），如果把emplace_back的参数改为initializer_list&lt;T&gt;则可行。 谜题解开了。","link":"/why-emplace_back-not-works/"},{"title":"atomic类和memory_order类","text":"","link":"/atomic-and-memory-order/"},{"title":"memory barrier","text":"根据上一篇文章https://vinci-897.github.io/volatile-in-cpp/中memory order部分提到的内容，我们知道，不同的cpu有不同的memory model和memory order，这导致cpu会对代码进行重排序，虽然单线程上编译器和cpu对代码的重排序都不会导致最终结果的不同，但当代码在一个cpu核心上执行时，由于多核缓存不同步等问题，其他的cpu核心会看到与原有代码顺序不同的访存顺序，这就是我们所说的乱序执行，这会引起一些问题。 编译期重排序已经在上一篇文章中描述过，因此本文中，我们所说的都是cpu内存模型导致的指令重排序。并且，编译器重排是从单线程角度考虑的，重排时会保证单线程逻辑不变，而cpu乱序执行，对于单核cpu内部看来，访存顺序也是不会改变的，仅仅是对其他cpu来说顺序改变。 有些时候我们会思考，存在分支情况下是否会重排，比如if (a == 1) b = 2;里，store b是否会被排序到load a前面？由于分支预测功能和流水线的存在，答案是会的，但如果后续发现a!=1，if分支最终没有进入，那么这次store b是无效的，cpu会采用另一分支或直接导致流水线暂停。 内存屏障指令在x86架构中，Load、Load， Load、Store， Store、Store这三种是不允许发生重排的（我们说的重排不一定是真正的重排，而是在其他核心看来访存行为的顺序变化），只有Store、Load这种被允许重排成Load、Store（即Stores after loads）。x86只允许store load指令的顺序交换，但这仅限于交换不同变量的store和load，因为对于同一变量的store load序列，这种交换显然是错误的，cpu很明白不能交换同一个变量的store load指令序列。 https://stackoverflow.com/questions/20316124/does-it-make-any-sense-to-use-the-lfence-instruction-on-x86-x86-64-processors 123456789101112131415void procedure0() { flag[0] = true; turn = 1; //1 while (flag[1] &amp;&amp; (turn == 1));//2 gCount++; flag[0] = false;}void procedure1() { flag[1] = true; turn = 0;//3 while (flag[0] &amp;&amp; (turn == 0));//4 gCount++; flag[1] = false;} 上述代码是著名的peterson算法，用于控制两个线程互斥访问临界区，这个算法在不允许任何类型的重排序时是完美的，然而，这个算法也是x86 cpu可能出现异常情况的标志性案例，因为在同一个函数中，x86 cpu会颠倒store flag[0]和之后while中load flag[1]的顺序，当两个线程都不在临界区时，两个flag都为false，此时两个while的flag都被提前load进寄存器，在之后while判断时，第一个条件都必然被满足，这样会导致flag失去作用，而turn一个变量是不能保证互斥的，按照代码注释中1234的顺序执行，两个线程会同时进入临界区。 上面这张图来自intel的开发手册，可以看出，mfence前面和后面的load store都不能越过mfence，sfence前面和后面的store不能越过sfence，lfence比较特殊，他的效果在前后不是对称的，lfence前面的load不能到后面，lfence后面的load store不能到前面。 mfence的功能是，在后面的load store全局可见之前，前面的load store都要全局可见；sfence的功能是后面的store全局可见之前，前面的store都要全局可见；lfence的功能是后面的load store全局可见之间，前面的load都要全局可见。 比如说，如果有一条mfence指令，那么不管cpu0的硬件如何安排指令顺序，其他cpu都可以安全地认为，cpu0是先进行了前面的load store再进行了后面的load store。 有时我们会觉得，load load乱序没有影响，请看上图，按照正常的顺序r，2应该等于NEW。然而，如果C2的L2被放到了L1前面，发生load load乱序，且C1C2按照L2、S1、S2，L1、B1的顺序执行，那么r2会被赋值为0，这是不对的。 四种乱序都会对这个程序产生影响，具体内容引自https://aijishu.com/a/1060000000222715 注意，即使如此，mfence也并不等于sfence + lfence，仔细思考一下，会发现sfence + lfence时，无法阻止store load乱序，如果，lfence在sfence前，那么前面的store可以被变换到lfence和sfence之间，后面的load也可以到lfence和sfence之间，所以store仍然有可能跑到load后面；如果sfence在lfence之前，那么是可以阻止store load乱序的，但mfence只有一条指令并且可以阻止任何形式的乱序，因此我们可以发现，sfence + lfence != mfence。 我们所说的乱序/顺序改变都是指多核场景下在cpu1看来，cpu0的访存指令执行顺序与代码顺序不同，既然这样，我们之前说到x86根本不会出现除store load的乱序，那么也就是说，在多线程缓存/内存一致性这个问题上，lfence和sfence根本没有意义，他们两个所能阻止的乱序在x86上压根就不会发生。（x86在目前被认为是使用了tso内存模型，这种模型比较严格） 是的，lfence和sfence在多线程上没有意义，但这不代表他没有任何作用，实际上这两种指令在硬件上会做一些操作，且确确实实的能阻止某些load store指令的全局可见性刷新，对性能优化会起到一定作用。https://www.zhihu.com/question/29465982 arm架构的内存模型十分复杂，且没有这么多限制，会出现更多的乱序情况。","link":"/memory-barrier/"},{"title":"volatile in c&#x2F;cpp","text":"volatile的行为对于c/cpp中的volatile关键字，cpp标准中有如下规定（其实c也是类似的）： https://vinci-897.github.io/cppwp/n4868/dcl.type.cv#6 https://en.cppreference.com/w/cpp/language/cv 从上述规定中可以看出，volatile关键字的存在主要是避免编译器对这一变量进行有侵略性的优化，volatile变量的访问1不能够被优化掉，2也不能够被和其他volatile变量的访问之间变换顺序。个人认为，前者主要是指以下情况： 12int x = 1;cout &lt;&lt; x; 在这种情况中，x可能被外部状态改变，如MMIO中硬件状态改变、信号处理函数改变、可能被汇编实现的setjmp/longjmp改变等，但编译器在优化时只考虑作为单线程运行的流程，因此可能会让cout直接输出1。（也可能是被其他线程改变，但是本文讨论的volatile不能阻止多线程的问题） 1234int x = 0;while(x) { cout &lt;&lt; 123;} 同样的原因，编译器可能会直接删除掉while循环，或者在while中只使用寄存器中存储的x值。 123456789int x = 1;void sig_handler(int signum) { x = 0;}int main() { while(x) { cout &lt;&lt; 123; }} 代码可能会被编译成一个while(true)的死循环，或者在while中只使用寄存器中存储的x值，编译器不会考虑x被内存中的signal_handler修改的情况，所以即使信号被触发，也不会跳出循环。因此，volatile可以被用于以下几种情况：与硬件进行MMIO交互/信号处理函数修改/内联汇编，可以发现，正如标准中所说的那样，volatile可以阻止编译器的这种行为，告知编译器这一变量可能被本部分代码流程之外的行为修改，但volatile和下面说的内存屏障指令不一样，volatile只能在编译器的优化中起作用，不能像真正的内存屏障一样影响cache以及memory model。 volatile不应该被用于多线程共享变量在上述的内容中，我们提到，其他线程的修改也会导致编译器的优化变得不再正确，那么我们能否通过使用volatile变量解决多线程之间变量修改的同步呢？。我们知道，除了在将c/cpp语言编译成机器语言代码时，会被编译器改变其执行顺序之外，cpu在执行时还会对指令进行乱序执行，这种优化在单线程时会保证访存结果与乱序前相同，然而对于多核来说，可能不再正确。同时，刚刚说到，cpu在访问内存时还会使用cache，多核之间的cache可能会不同步，导致不同线程看到的变量修改顺序不同，虽然缓存一致性协议能够保证多核缓存的同步，但是由于大多数cpu并没有实现完美的缓存一致性协议，或者他们实现的一致性并不保证在任何时刻的多核缓存一致，而是保留了自己的内存模型（因此他们也提供了内存屏障指令），并且存在store buffer一类的延迟写入策略(store buffer问题的相关介绍)，因此缓存不同步依然会导致多个线程在访问内存上的同一地址时得到各自缓存中不同的值。这几个问题导致我们即使阻止了编译器优化对操作顺序的影响，也不能阻止cpu乱序执行和cache的影响（这两个问题需要内存屏障来解决），然而volatile只能解决编译器的问题，volatile不会被编译为内存屏障指令，因此volatile无法解决多线程之间变量的同步问题。 内存屏障我们之前提到了乱序执行和不同架构内存模型导致的cache不同步问题，x86/x64/arm架构都提供了各自的内存屏障指令。 在MESI一致性协议中，可以由多个cpu同时持有一个数据的缓存，也可以由一个cpu持有一个数据的缓存，但是如果一个cpu0想要修改一个地址，那么必须先要求所有持有这一地址的cpu的缓存失效。如果一个cpu0想要读取一个地址，同时这个地址刚刚被cpu1修改过，那么应该由cpu1的缓存返回这一地址的值，而不是由内存返回。引自https://zhuanlan.zhihu.com/p/546562532 在cpu中存在上图中的结构，store buffer和invalid queue，store buffer的作用是将缓存同步的任务分离出cpu，以防让cpu在缓存同步时等待，当cpu0要修改一个内存地址时，先把数据放入store buffer，然后通知cpu1让缓存失效，当cpu1反馈完成消息后，cpu0的store buffer会真正的修改cache，在这期间cpu0会直接使用自己store buffer中的新值，（但这里可以很容易的想到，其他cpu还没有来得及让缓存失效时如果使用了这一地址，那么我们的缓存就出现了不一致）。invalid queue的作用是当cpu1收到缓存失效消息时，不必真正的等待缓存行被设置成失效，而是先存入队列等待慢慢消费，直接给cpu0返回成功（很容易想到在invalid queue来不及消费时，如果访问了这个地址，也会导致缓存不同步）。 所谓内存屏障的功能就是控制屏障指令两侧的读写消息顺序，比如保证在内存屏障后的语句执行前，内存屏障前产生的invalid queue和store buffer消息必须被消费完，这不光可以解决缓存的一致性，同时也可以保证在任何一个cpu核心看来，都是在内存屏障前的修改完成后，内存屏障后的修改才开始，因此内存屏障可以同时解决上述两个问题。具体的内存屏障分类单独开一篇文章，之后再写。 ps：x64的内存模型相比arm一类来说较为严格，一些类型的缓存不一致是不会发生的，因此如果仅限于x64架构，那么或许可以仅仅使用volatile来控制多线程共享变量，但这不利于代码移植。 memory ordermemory order是指cpu在实际执行指令时语句的顺序，这种顺序在内存模型不严格的情况下可以与我们书写代码的顺序出现很大不同。 cpp语言中提供了atomic类，这个类在默认情况下会基于内存屏障实现最严格的内存模型，也就是说对于atomic对象的读取和写入看上去会与我们编写代码的顺序相同，但也可以通过cpp提供的memory_order类来控制。 atomic和memory_order的组合，也应当是我们在任何架构上编写多线程代码的工具，这样的代码更便于移植，而不是依赖于volatile配合特定架构的内存模型。 asm volatile (“” : : : “memory”)这是一种编译期内存屏障，与上述的内存屏障指令是不同的，编译器内存屏障不能控制invalid queue和store buffer这种对编译器透明的组件，在编译器眼里cache和memory应该是一体的，一般来说，编译器并不知道自己load或者store的目标到底是cache还是memory。 __asm__在gcc等编译器中表示内联汇编语言。 __volatile__的作用和上面描述的一样，主要作用是防止这一句和其他volatile访问的顺序被编译器改变。 memory的意思是，这一句汇编内联会对memory产生影响，以此告诉编译器，应该考虑到这对局部变量和全局变量的影响，所以不要重排这之前和这之后访存指令的顺序，也就是说这可以保证之前的访存都发生在这之后的访存之前，同时 由于这条语句声明其内联的汇编会对内存造成影响，这个指令之前所有暂存在寄存器中以便于后续访问的变量，编译器应该在这条语句之前将其写回内存。 这个内存屏障主要用于阻止编译器对访存指令的重排，虽然它不能阻止cpu内存模型本身引起的指令重排序，但是在一些拥有strict memory order的架构（比如一些x86cpu）上，这个编译期内存屏障就能够阻止绝大部分的指令重排序（因为在严格的架构上，cpu不允许大多数类型的重排序）。 https://stackoverflow.com/questions/67943540/why-can-asm-volatile-memory-serve-as-a-compiler-barrier","link":"/volatile-in-cpp/"}],"tags":[],"categories":[],"pages":[]}